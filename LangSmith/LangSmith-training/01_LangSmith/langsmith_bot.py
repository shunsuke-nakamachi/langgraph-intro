"""
LangSmith Integrationï¼ˆãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ãƒ»ãƒ‡ãƒãƒƒã‚°ï¼‰

ã“ã®å®Ÿè£…ã§ã¯ã€LangSmithã‚’ä½¿ã£ã¦LangGraphã®å®Ÿè¡Œéç¨‹ã‚’å¯è¦–åŒ–ãƒ»ãƒ‡ãƒãƒƒã‚°ã™ã‚‹æ–¹æ³•ã‚’å­¦ã³ã¾ã™ã€‚

ã€å­¦ã¶ã“ã¨ã€‘
1. LangSmithã®åŸºæœ¬è¨­å®šï¼ˆç’°å¢ƒå¤‰æ•°ã€APIã‚­ãƒ¼ï¼‰
2. ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ã®æœ‰åŠ¹åŒ–
3. LangSmith UIã§ã®å®Ÿè¡Œãƒ­ã‚°ç¢ºèª
4. ãƒ‡ãƒãƒƒã‚°ã®æ´»ç”¨æ–¹æ³•
5. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ

ã€å‰ææ¡ä»¶ã€‘
1. LangSmithã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®ä½œæˆï¼ˆç„¡æ–™ï¼‰
   - https://smith.langchain.com/ ã«ã‚¢ã‚¯ã‚»ã‚¹
   - ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’ä½œæˆã—ã¦APIã‚­ãƒ¼ã‚’å–å¾—
2. ç’°å¢ƒå¤‰æ•°ã®è¨­å®š
   - .envãƒ•ã‚¡ã‚¤ãƒ«ã«ä»¥ä¸‹ã‚’è¿½åŠ :
     LANGCHAIN_TRACING_V2=true
     LANGCHAIN_API_KEY=your_api_key_here
     LANGCHAIN_PROJECT=langgraph-practice  # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåï¼ˆä»»æ„ï¼‰
"""
import asyncio
from typing import TypedDict, Annotated, List
from dotenv import load_dotenv
import os

from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages

# -------------------------------------------------
# 1. ç’°å¢ƒè¨­å®šã¨LangSmithã®æœ‰åŠ¹åŒ–
# -------------------------------------------------
load_dotenv()

# LangSmithã®è¨­å®šç¢ºèª
tracing_enabled = os.getenv("LANGCHAIN_TRACING_V2", "false").lower() == "true"
api_key = os.getenv("LANGCHAIN_API_KEY")
project_name = os.getenv("LANGCHAIN_PROJECT", "langgraph-practice")

if tracing_enabled and api_key:
    print(f"âœ… LangSmith ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ãŒæœ‰åŠ¹ã§ã™")
    print(f"   ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå: {project_name}")
    print(f"   LangSmith UI: https://smith.langchain.com/\n")
else:
    print("âš ï¸  LangSmith ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ãŒç„¡åŠ¹ã§ã™")
    print("   .envãƒ•ã‚¡ã‚¤ãƒ«ã«ä»¥ä¸‹ã‚’è¨­å®šã—ã¦ãã ã•ã„:")
    print("   LANGCHAIN_TRACING_V2=true")
    print("   LANGCHAIN_API_KEY=your_api_key_here")
    print("   LANGCHAIN_PROJECT=langgraph-practice\n")

llm = ChatOpenAI(model="gpt-4o-mini")

# -------------------------------------------------
# 2. State å®šç¾©
# -------------------------------------------------
class State(TypedDict):
    messages: Annotated[List, add_messages]
    query: str
    research_result: str
    summary: str

# -------------------------------------------------
# 3. ãƒãƒ¼ãƒ‰å®šç¾©
# -------------------------------------------------

def researcher_node(state: State) -> dict:
    """ãƒªã‚µãƒ¼ãƒãƒãƒ¼ãƒ‰: è³ªå•ã«ã¤ã„ã¦æƒ…å ±ã‚’èª¿ã¹ã‚‹"""
    print("\n[Researcher] ãƒªã‚µãƒ¼ãƒä¸­...")
    
    query = state.get("query", "")
    
    messages = [
        SystemMessage(content="ã‚ãªãŸã¯æƒ…å ±ã‚’èª¿ã¹ã‚‹å°‚é–€å®¶ã§ã™ã€‚è³ªå•ã«å¯¾ã—ã¦æ­£ç¢ºã§æœ‰ç”¨ãªæƒ…å ±ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚"),
        HumanMessage(content=f"ã€Œ{query}ã€ã«ã¤ã„ã¦ã€é‡è¦ãªæƒ…å ±ã‚’3ã¤æŒ™ã’ã¦ãã ã•ã„ã€‚")
    ]
    
    response = llm.invoke(messages)
    research_result = response.content
    
    print(f"  âœ… [Researcher] å®Œäº†")
    return {"research_result": research_result}

def analyzer_node(state: State) -> dict:
    """åˆ†æãƒãƒ¼ãƒ‰: ãƒªã‚µãƒ¼ãƒçµæœã‚’åˆ†æã™ã‚‹"""
    print("\n[Analyzer] åˆ†æä¸­...")
    
    query = state.get("query", "")
    research_result = state.get("research_result", "")
    
    messages = [
        SystemMessage(content="ã‚ãªãŸã¯æƒ…å ±ã‚’åˆ†æã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚ãƒªã‚µãƒ¼ãƒçµæœã‚’åˆ†æã—ã€è¦ç‚¹ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚"),
        HumanMessage(content=f"""
è³ªå•: {query}

ãƒªã‚µãƒ¼ãƒçµæœ:
{research_result}

ä¸Šè¨˜ã®ãƒªã‚µãƒ¼ãƒçµæœã‚’åˆ†æã—ã€è³ªå•ã«å¯¾ã™ã‚‹å›ç­”ã‚’200æ–‡å­—ç¨‹åº¦ã§ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚
""")
    ]
    
    response = llm.invoke(messages)
    summary = response.content
    
    print(f"  âœ… [Analyzer] å®Œäº†")
    return {"summary": summary}

def finalizer_node(state: State) -> dict:
    """æœ€çµ‚åŒ–ãƒãƒ¼ãƒ‰: æœ€çµ‚çš„ãªå›ç­”ã‚’æ•´å½¢ã™ã‚‹"""
    print("\n[Finalizer] æœ€çµ‚åŒ–ä¸­...")
    
    query = state.get("query", "")
    summary = state.get("summary", "")
    
    messages = [
        SystemMessage(content="ã‚ãªãŸã¯å›ç­”ã‚’æ•´å½¢ã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚åˆ†ã‹ã‚Šã‚„ã™ãèª­ã¿ã‚„ã™ã„å½¢å¼ã§å›ç­”ã‚’æ•´å½¢ã—ã¦ãã ã•ã„ã€‚"),
        HumanMessage(content=f"""
è³ªå•: {query}

åˆ†æçµæœ:
{summary}

ä¸Šè¨˜ã®åˆ†æçµæœã‚’å…ƒã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®æœ€çµ‚å›ç­”ã‚’æ•´å½¢ã—ã¦ãã ã•ã„ã€‚
""")
    ]
    
    response = llm.invoke(messages)
    final_answer = response.content
    
    print(f"  âœ… [Finalizer] å®Œäº†")
    return {"messages": [AIMessage(content=final_answer)]}

# -------------------------------------------------
# 4. ã‚°ãƒ©ãƒ•æ§‹ç¯‰
# -------------------------------------------------
builder = StateGraph(State)

builder.add_node("researcher", researcher_node)
builder.add_node("analyzer", analyzer_node)
builder.add_node("finalizer", finalizer_node)

builder.add_edge(START, "researcher")
builder.add_edge("researcher", "analyzer")
builder.add_edge("analyzer", "finalizer")
builder.add_edge("finalizer", END)

graph = builder.compile()

# -------------------------------------------------
# 5. å®Ÿè¡Œ
# -------------------------------------------------
async def main():
    print("--- LangSmith Integration Bot é–‹å§‹ ---\n")
    
    if tracing_enabled:
        print("ğŸ“Š LangSmith UIã§å®Ÿè¡Œãƒ­ã‚°ã‚’ç¢ºèªã§ãã¾ã™:")
        print(f"   https://smith.langchain.com/o/{os.getenv('LANGCHAIN_ORG_ID', 'default')}/projects/p/{project_name}\n")
    
    test_queries = [
        "LangGraphã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ",
        "ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ ã®åˆ©ç‚¹ã¯ï¼Ÿ",
        "ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã¯ï¼Ÿ"
    ]
    
    for i, query in enumerate(test_queries, 1):
        print(f"\n{'='*60}")
        print(f"ã‚±ãƒ¼ã‚¹{i}: {query}")
        print(f"{'='*60}\n")
        
        initial_state = {
            "messages": [HumanMessage(content=query)],
            "query": query,
            "research_result": "",
            "summary": ""
        }
        
        # ã‚°ãƒ©ãƒ•ã‚’å®Ÿè¡Œ
        # LangSmithãŒè‡ªå‹•çš„ã«å®Ÿè¡Œãƒ­ã‚°ã‚’è¨˜éŒ²ã—ã¾ã™
        final_state = None
        async for event in graph.astream_events(initial_state, version="v1"):
            if event["event"] == "on_chain_end":
                name = event.get("name", "")
                if name == "finalizer":
                    output = event["data"]["output"]
                    if "messages" in output and output["messages"]:
                        last_msg = output["messages"][-1]
                        if isinstance(last_msg, AIMessage):
                            print(f"\n[Final Answer]\n{last_msg.content}")
        
        print("\n" + "-"*60)
        
        # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹é–“ã§å°‘ã—å¾…æ©Ÿï¼ˆAPIãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–ï¼‰
        if i < len(test_queries):
            await asyncio.sleep(1)
    
    if tracing_enabled:
        print(f"\n{'='*60}")
        print("ğŸ“Š LangSmith UIã§è©³ç´°ã‚’ç¢ºèª:")
        print(f"   https://smith.langchain.com/o/{os.getenv('LANGCHAIN_ORG_ID', 'default')}/projects/p/{project_name}")
        print(f"{'='*60}\n")
        print("LangSmith UIã§ã¯ä»¥ä¸‹ãŒç¢ºèªã§ãã¾ã™:")
        print("  - å„ãƒãƒ¼ãƒ‰ã®å®Ÿè¡Œæ™‚é–“")
        print("  - LLMã¸ã®å…¥åŠ›ã¨å‡ºåŠ›")
        print("  - ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡")
        print("  - ã‚¨ãƒ©ãƒ¼ã®è©³ç´°")
        print("  - Stateã®å¤‰åŒ–")

if __name__ == "__main__":
    asyncio.run(main())

