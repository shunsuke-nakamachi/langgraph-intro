"""
Error Handling & Recoveryï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨ãƒªã‚«ãƒãƒªãƒ¼ï¼‰

ã“ã®å®Ÿè£…ã§ã¯ã€LangGraphã§ãƒãƒ¼ãƒ‰å®Ÿè¡Œæ™‚ã®ã‚¨ãƒ©ãƒ¼å‡¦ç†ã¨ãƒªãƒˆãƒ©ã‚¤ãƒ­ã‚¸ãƒƒã‚¯ã‚’å­¦ã³ã¾ã™ã€‚

ã€å­¦ã¶ã“ã¨ã€‘
1. åŸºæœ¬çš„ãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ï¼ˆtry-exceptï¼‰
2. ãƒªãƒˆãƒ©ã‚¤ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆtenacityãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ä½¿ç”¨ï¼‰
3. ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå‡¦ç†
4. ã‚¨ãƒ©ãƒ¼çŠ¶æ…‹ã®ç®¡ç†ã¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
5. ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã®è¨˜éŒ²
"""
import asyncio
import time
import random
from typing import TypedDict, Annotated, List, Optional
from dotenv import load_dotenv

from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from tenacity import (
    retry,
    stop_after_attempt,
    wait_exponential,
    retry_if_exception_type,
    RetryError
)

# -------------------------------------------------
# 1. ç’°å¢ƒè¨­å®š
# -------------------------------------------------
load_dotenv()

llm = ChatOpenAI(model="gpt-4o-mini")

# -------------------------------------------------
# 2. State å®šç¾©
# -------------------------------------------------
class State(TypedDict):
    messages: Annotated[List, add_messages]
    query: str
    result: Optional[str]
    error_count: int  # ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿå›æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
    last_error: Optional[str]  # æœ€å¾Œã«ç™ºç”Ÿã—ãŸã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    retry_count: int  # ãƒªãƒˆãƒ©ã‚¤å›æ•°

# -------------------------------------------------
# 3. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ç”¨ã®ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
# -------------------------------------------------

def log_error(node_name: str, error: Exception, attempt: int = 1):
    """ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’è¨˜éŒ²"""
    error_msg = f"[{node_name}] ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ (è©¦è¡Œå›æ•°: {attempt}): {type(error).__name__}: {str(error)}"
    print(f"  âš ï¸  {error_msg}")
    return error_msg

# -------------------------------------------------
# 4. ãƒãƒ¼ãƒ‰å®šç¾©ï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ãï¼‰
# -------------------------------------------------

def unreliable_api_call(query: str) -> str:
    """
    ä¸å®‰å®šãªå¤–éƒ¨APIå‘¼ã³å‡ºã—ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
    50%ã®ç¢ºç‡ã§ã‚¨ãƒ©ãƒ¼ã‚’ç™ºç”Ÿã•ã›ã‚‹ï¼ˆãƒ‡ãƒ¢ç”¨ï¼‰
    """
    # ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚¨ãƒ©ãƒ¼ã‚’ç™ºç”Ÿã•ã›ã‚‹ï¼ˆãƒ‡ãƒ¢ç”¨ï¼‰
    if random.random() < 0.5:
        raise ConnectionError(f"APIæ¥ç¶šã‚¨ãƒ©ãƒ¼: {query} ã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸ")
    
    # æ­£å¸¸ãªå ´åˆ
    return f"API Response for: {query}"

@retry(
    stop=stop_after_attempt(3),  # æœ€å¤§3å›ã¾ã§ãƒªãƒˆãƒ©ã‚¤
    wait=wait_exponential(multiplier=1, min=1, max=10),  # æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ï¼ˆ1ç§’ã€2ç§’ã€4ç§’...ï¼‰
    retry=retry_if_exception_type((ConnectionError, TimeoutError)),  # ã“ã‚Œã‚‰ã®ã‚¨ãƒ©ãƒ¼ã®ã¿ãƒªãƒˆãƒ©ã‚¤
    reraise=True  # æœ€çµ‚çš„ã«å¤±æ•—ã—ãŸå ´åˆã¯ä¾‹å¤–ã‚’å†ç™ºç”Ÿ
)
def api_node_with_retry(state: State) -> dict:
    """ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãã®APIå‘¼ã³å‡ºã—ãƒãƒ¼ãƒ‰"""
    print("\n[API Node] å¤–éƒ¨APIã‚’å‘¼ã³å‡ºã—ä¸­...")
    
    query = state.get("query", "")
    retry_count = state.get("retry_count", 0)
    
    try:
        # ä¸å®‰å®šãªAPIå‘¼ã³å‡ºã—ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        result = unreliable_api_call(query)
        print(f"  âœ… [API Node] æˆåŠŸ: {result}")
        return {
            "result": result,
            "retry_count": retry_count + 1,
            "error_count": 0  # æˆåŠŸã—ãŸã®ã§ã‚¨ãƒ©ãƒ¼ã‚«ã‚¦ãƒ³ãƒˆã‚’ãƒªã‚»ãƒƒãƒˆ
        }
    except (ConnectionError, TimeoutError) as e:
        # tenacityãŒè‡ªå‹•çš„ã«ãƒªãƒˆãƒ©ã‚¤ã™ã‚‹ãŒã€ãƒ­ã‚°ã¯è¨˜éŒ²
        log_error("API Node", e, retry_count + 1)
        raise  # tenacityã«ãƒªãƒˆãƒ©ã‚¤ã‚’å§”ã­ã‚‹
    except Exception as e:
        # ãƒªãƒˆãƒ©ã‚¤ã—ãªã„ã‚¨ãƒ©ãƒ¼ï¼ˆä¾‹: ValueErrorï¼‰
        log_error("API Node", e, retry_count + 1)
        return {
            "result": None,
            "error_count": state.get("error_count", 0) + 1,
            "last_error": str(e),
            "retry_count": retry_count + 1
        }

def llm_node_with_error_handling(state: State) -> dict:
    """ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ãã®LLMå‘¼ã³å‡ºã—ãƒãƒ¼ãƒ‰"""
    print("\n[LLM Node] LLMã‚’å‘¼ã³å‡ºã—ä¸­...")
    
    messages = state["messages"]
    error_count = state.get("error_count", 0)
    
    try:
        # LLMå‘¼ã³å‡ºã—ï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚„ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ï¼‰
        response = llm.invoke(messages)
        print(f"  âœ… [LLM Node] æˆåŠŸ")
        return {
            "messages": [response],
            "error_count": 0  # æˆåŠŸã—ãŸã®ã§ã‚¨ãƒ©ãƒ¼ã‚«ã‚¦ãƒ³ãƒˆã‚’ãƒªã‚»ãƒƒãƒˆ
        }
    except Exception as e:
        # LLMå‘¼ã³å‡ºã—ã®ã‚¨ãƒ©ãƒ¼ï¼ˆãƒ¬ãƒ¼ãƒˆåˆ¶é™ã€ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãªã©ï¼‰
        error_msg = log_error("LLM Node", e)
        
        # ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        fallback_message = AIMessage(
            content="ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚ä¸€æ™‚çš„ã«ã‚µãƒ¼ãƒ“ã‚¹ã«æ¥ç¶šã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ã—ã°ã‚‰ãã—ã¦ã‹ã‚‰å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚"
        )
        
        return {
            "messages": [fallback_message],
            "error_count": error_count + 1,
            "last_error": error_msg
        }

def timeout_simulation_node(state: State) -> dict:
    """ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã™ã‚‹ãƒãƒ¼ãƒ‰"""
    print("\n[Timeout Node] é•·æ™‚é–“å‡¦ç†ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆä¸­...")
    
    # ãƒ©ãƒ³ãƒ€ãƒ ã«é•·æ™‚é–“å‡¦ç†ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆï¼ˆãƒ‡ãƒ¢ç”¨ï¼‰
    processing_time = random.uniform(0.5, 3.0)
    
    if processing_time > 2.0:
        # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã¨ã¿ãªã™
        raise TimeoutError(f"å‡¦ç†ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸï¼ˆå‡¦ç†æ™‚é–“: {processing_time:.2f}ç§’ï¼‰")
    
    time.sleep(processing_time)
    print(f"  âœ… [Timeout Node] æˆåŠŸï¼ˆå‡¦ç†æ™‚é–“: {processing_time:.2f}ç§’ï¼‰")
    return {"result": f"å‡¦ç†å®Œäº†ï¼ˆ{processing_time:.2f}ç§’ï¼‰"}

@retry(
    stop=stop_after_attempt(2),  # æœ€å¤§2å›ã¾ã§ãƒªãƒˆãƒ©ã‚¤
    wait=wait_exponential(multiplier=0.5, min=0.5, max=2),
    retry=retry_if_exception_type(TimeoutError),
    reraise=True
)
def timeout_node_with_retry(state: State) -> dict:
    """ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãƒªãƒˆãƒ©ã‚¤ä»˜ããƒãƒ¼ãƒ‰"""
    try:
        return timeout_simulation_node(state)
    except TimeoutError as e:
        log_error("Timeout Node", e)
        raise  # tenacityã«ãƒªãƒˆãƒ©ã‚¤ã‚’å§”ã­ã‚‹

def error_recovery_node(state: State) -> dict:
    """ã‚¨ãƒ©ãƒ¼çŠ¶æ…‹ã‚’ç¢ºèªã—ã€å¿…è¦ã«å¿œã˜ã¦ãƒªã‚«ãƒãƒªãƒ¼ã™ã‚‹ãƒãƒ¼ãƒ‰"""
    print("\n[Recovery Node] ã‚¨ãƒ©ãƒ¼çŠ¶æ…‹ã‚’ç¢ºèªä¸­...")
    
    error_count = state.get("error_count", 0)
    last_error = state.get("last_error", "")
    result = state.get("result")
    
    if error_count > 0:
        print(f"  âš ï¸  [Recovery Node] ã‚¨ãƒ©ãƒ¼ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸï¼ˆå›æ•°: {error_count}ï¼‰")
        print(f"  ğŸ“ [Recovery Node] æœ€å¾Œã®ã‚¨ãƒ©ãƒ¼: {last_error}")
        
        # ã‚¨ãƒ©ãƒ¼ãŒå¤šã™ãã‚‹å ´åˆã¯ã€ä»£æ›¿å‡¦ç†ã‚’ææ¡ˆ
        if error_count >= 3:
            recovery_message = AIMessage(
                content="è¤‡æ•°ã®ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…ã«é€£çµ¡ã™ã‚‹ã‹ã€åˆ¥ã®æ–¹æ³•ã‚’ãŠè©¦ã—ãã ã•ã„ã€‚"
            )
            return {
                "messages": [recovery_message],
                "result": "ã‚¨ãƒ©ãƒ¼ãŒå¤šã™ãã‚‹ãŸã‚ã€å‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã—ãŸ"
            }
        else:
            # ã‚¨ãƒ©ãƒ¼ãŒå°‘ãªã„å ´åˆã¯ã€å†è©¦è¡Œã‚’ä¿ƒã™
            recovery_message = AIMessage(
                content="ä¸€æ™‚çš„ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸãŒã€å‡¦ç†ã¯ç¶šè¡Œã—ã¾ã™ã€‚"
            )
            return {
                "messages": [recovery_message],
                "error_count": 0  # ãƒªã‚«ãƒãƒªãƒ¼ã—ãŸã®ã§ã‚¨ãƒ©ãƒ¼ã‚«ã‚¦ãƒ³ãƒˆã‚’ãƒªã‚»ãƒƒãƒˆ
            }
    else:
        print(f"  âœ… [Recovery Node] ã‚¨ãƒ©ãƒ¼ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
        return {}

# -------------------------------------------------
# 5. æ¡ä»¶åˆ†å²é–¢æ•°
# -------------------------------------------------

def check_error_state(state: State) -> str:
    """ã‚¨ãƒ©ãƒ¼çŠ¶æ…‹ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦æ¬¡ã®ãƒãƒ¼ãƒ‰ã‚’æ±ºå®š"""
    error_count = state.get("error_count", 0)
    result = state.get("result")
    
    # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã„ã‚‹ã€ã¾ãŸã¯çµæœãŒãªã„å ´åˆã¯ãƒªã‚«ãƒãƒªãƒ¼ãƒãƒ¼ãƒ‰ã¸
    if error_count > 0 or result is None:
        return "recovery"
    else:
        return "end"

# -------------------------------------------------
# 6. ã‚°ãƒ©ãƒ•æ§‹ç¯‰
# -------------------------------------------------
builder = StateGraph(State)

# ãƒãƒ¼ãƒ‰ã®è¿½åŠ 
builder.add_node("api_call", api_node_with_retry)
builder.add_node("llm_call", llm_node_with_error_handling)
builder.add_node("timeout_test", timeout_node_with_retry)
builder.add_node("recovery", error_recovery_node)

# ã‚¨ãƒƒã‚¸ã®è¿½åŠ 
builder.add_edge(START, "api_call")
builder.add_edge("api_call", "llm_call")
builder.add_edge("llm_call", "timeout_test")

# ã‚¨ãƒ©ãƒ¼çŠ¶æ…‹ã«å¿œã˜ãŸæ¡ä»¶åˆ†å²
builder.add_conditional_edges(
    "timeout_test",
    check_error_state,
    {
        "recovery": "recovery",
        "end": END
    }
)

builder.add_edge("recovery", END)

graph = builder.compile()

# -------------------------------------------------
# 7. å®Ÿè¡Œ
# -------------------------------------------------
async def main():
    print("--- Error Handling & Recovery Bot é–‹å§‹ ---\n")
    
    test_cases = [
        {
            "name": "ã‚±ãƒ¼ã‚¹1: æ­£å¸¸ãªå‡¦ç†",
            "query": "æ­£å¸¸ãªã‚¯ã‚¨ãƒªã£ã¦ãªã‚“ã§ã™ã‹ï¼Ÿ",
            "description": "ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãªã„å ´åˆã®å‹•ä½œã‚’ç¢ºèª"
        },
        {
            "name": "ã‚±ãƒ¼ã‚¹2: APIã‚¨ãƒ©ãƒ¼ï¼ˆãƒªãƒˆãƒ©ã‚¤æˆåŠŸï¼‰",
            "query": "APIã‚¨ãƒ©ãƒ¼ãƒ†ã‚¹ãƒˆã£ã¦ãªã‚“ã§ã™ã‹ï¼Ÿ",
            "description": "APIã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹ãŒã€ãƒªãƒˆãƒ©ã‚¤ã§æˆåŠŸã™ã‚‹å ´åˆ"
        },
        {
            "name": "ã‚±ãƒ¼ã‚¹3: ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¨ãƒ©ãƒ¼",
            "query": "ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãƒ†ã‚¹ãƒˆã£ã¦ãªã‚“ã§ã™ã‹ï¼Ÿ",
            "description": "ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãŒç™ºç”Ÿã™ã‚‹å ´åˆã®å‹•ä½œã‚’ç¢ºèª"
        }
    ]
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\n{'='*60}")
        print(f"{test_case['name']}")
        print(f"èª¬æ˜: {test_case['description']}")
        print(f"{'='*60}\n")
        
        initial_state = {
            "messages": [HumanMessage(content=test_case["query"])],
            "query": test_case["query"],
            "result": None,
            "error_count": 0,
            "last_error": None,
            "retry_count": 0
        }
        
        try:
            # ã‚°ãƒ©ãƒ•ã‚’å®Ÿè¡Œ
            final_state = None
            async for event in graph.astream_events(initial_state, version="v1"):
                if event["event"] == "on_chain_end":
                    name = event.get("name", "")
                    if name in ["llm_call", "recovery"]:
                        output = event["data"]["output"]
                        if "messages" in output and output["messages"]:
                            last_msg = output["messages"][-1]
                            if isinstance(last_msg, AIMessage):
                                print(f"\n[Final Message]\n{last_msg.content}")
            
            print(f"\n[æœ€çµ‚çŠ¶æ…‹]")
            print(f"  ã‚¨ãƒ©ãƒ¼å›æ•°: {initial_state.get('error_count', 0)}")
            print(f"  ãƒªãƒˆãƒ©ã‚¤å›æ•°: {initial_state.get('retry_count', 0)}")
            if initial_state.get("last_error"):
                print(f"  æœ€å¾Œã®ã‚¨ãƒ©ãƒ¼: {initial_state['last_error']}")
        
        except RetryError as e:
            print(f"\n  âŒ æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°ã«é”ã—ã¾ã—ãŸ: {e}")
        except Exception as e:
            print(f"\n  âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
        finally:
            # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã‚‚ã‚°ãƒ©ãƒ•æ§‹é€ ã‚’è¡¨ç¤º
            print(f"\n[ã‚°ãƒ©ãƒ•æ§‹é€ ]")
            graph_ascii = graph.get_graph().print_ascii()
            print(graph_ascii)
        
        print("\n" + "-"*60)
        
        # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹é–“ã§å°‘ã—å¾…æ©Ÿï¼ˆAPIãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–ï¼‰
        if i < len(test_cases):
            await asyncio.sleep(1)

if __name__ == "__main__":
    asyncio.run(main())

